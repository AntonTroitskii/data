{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "learntools_metadata": {
   "lesson_index": 4,
   "type": "exercise"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**This notebook is an exercise in the [Python](https://www.kaggle.com/learn/python) course.  You can reference the tutorial at [this link](https://www.kaggle.com/colinmorris/loops-and-list-comprehensions).**\n",
    "\n",
    "---\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try It Yourself\n",
    "\n",
    "With all you've learned, you can start writing much more interesting programs. See if you can solve the problems below.\n",
    "\n",
    "As always, run the setup code below before working on the questions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from learntools.core import binder; binder.bind(globals())\n",
    "from learntools.python.ex5 import *\n",
    "print('Setup complete.')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring repeated attempt to bind to globals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.\n",
    "\n",
    "Have you ever felt debugging involved a bit of luck? The following program has a bug. Try to identify the bug and fix it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def has_lucky_number(nums):\n",
    "    \"\"\"Return whether the given list of numbers is lucky. A lucky list contains\n",
    "    at least one number divisible by 7.\n",
    "    \"\"\"\n",
    "    for num in nums:\n",
    "        if num % 7 == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try to identify the bug and fix it in the cell below:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def has_lucky_number(nums):\n",
    "    \"\"\"Return whether the given list of numbers is lucky. A lucky list contains\n",
    "    at least one number divisible by 7.\n",
    "    \"\"\"\n",
    "    res = False\n",
    "    if nums:\n",
    "        for num in nums:\n",
    "            if num % 7 == 0:\n",
    "                res = True\n",
    "    return res\n",
    "\n",
    "# Check your answer\n",
    "q1.check()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"1_EarlyExitDebugging\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Correct: \n\nRemember that `return` causes a function to exit immediately. So our original implementation always ran for just one iteration. We can only return `False` if we've looked at every element of the list (and confirmed that none of them are lucky). Though we can return early if the answer is `True`:\n\n```python\ndef has_lucky_number(nums):\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    # We've exhausted the list without finding a lucky number\n    return False\n```\n\nHere's a one-line version using a list comprehension with Python's `any` function (you can read about what it does by calling `help(any)`):\n\n```python\ndef has_lucky_number(nums):\n    return any([num % 7 == 0 for num in nums])\n```",
      "text/markdown": "<span style=\"color:#33cc33\">Correct:</span> \n\nRemember that `return` causes a function to exit immediately. So our original implementation always ran for just one iteration. We can only return `False` if we've looked at every element of the list (and confirmed that none of them are lucky). Though we can return early if the answer is `True`:\n\n```python\ndef has_lucky_number(nums):\n    for num in nums:\n        if num % 7 == 0:\n            return True\n    # We've exhausted the list without finding a lucky number\n    return False\n```\n\nHere's a one-line version using a list comprehension with Python's `any` function (you can read about what it does by calling `help(any)`):\n\n```python\ndef has_lucky_number(nums):\n    return any([num % 7 == 0 for num in nums])\n```\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "q1.hint()\n",
    "#q1.solution()"
   ],
   "metadata": {},
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"1_EarlyExitDebugging\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Hint: How many times does the body of the loop run for a list of length n? (If you're not sure, try adding a `print()` call on the line before the `if`.)",
      "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> How many times does the body of the loop run for a list of length n? (If you're not sure, try adding a `print()` call on the line before the `if`.)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2.\n\n### a.\nLook at the Python expression below. What do you think we'll get when we run it? When you've made your prediction, uncomment the code and run the cell to see if you were right.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#[1, 2, 3, 4] > 2",
   "metadata": {},
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### b\nR and Python have some libraries (like numpy and pandas) compare each element of the list to 2 (i.e. do an 'element-wise' comparison) and give us a list of booleans like `[False, False, True, True]`. \n\nImplement a function that reproduces this behaviour, returning a list of booleans corresponding to whether the corresponding element is greater than n.\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def elementwise_greater_than(L, thresh):\n    \"\"\"Return a list with the same length as L, where the value at index i is \n    True if L[i] is greater than thresh, and False otherwise.\n    \n    >>> elementwise_greater_than([1, 2, 3, 4], 2)\n    [False, False, True, True]\n    \"\"\"\n    pass\n\n# Check your answer\nq2.check()",
   "metadata": {},
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 4, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_ElementWiseComparison\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Check: When you've updated the starter code, `check()` will tell you whether your code is correct. ",
      "text/markdown": "<span style=\"color:#ccaa33\">Check:</span> When you've updated the starter code, `check()` will tell you whether your code is correct. "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "#q2.solution()",
   "metadata": {},
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3.\n\nComplete the body of the function below according to its docstring.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def menu_is_boring(meals):\n    \"\"\"Given a list of meals served over some period of time, return True if the\n    same meal has ever been served two days in a row, and False otherwise.\n    \"\"\"\n    pass\n\n# Check your answer\nq3.check()",
   "metadata": {},
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 4, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"3_BoringMenu\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Check: When you've updated the starter code, `check()` will tell you whether your code is correct. ",
      "text/markdown": "<span style=\"color:#ccaa33\">Check:</span> When you've updated the starter code, `check()` will tell you whether your code is correct. "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "#q3.hint()\n#q3.solution()",
   "metadata": {},
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. <span title=\"A bit spicy\" style=\"color: darkgreen \">🌶️</span>\n\nNext to the Blackjack table, the Python Challenge Casino has a slot machine. You can get a result from the slot machine by calling `play_slot_machine()`. The number it returns is your winnings in dollars. Usually it returns 0.  But sometimes you'll get lucky and get a big payday. Try running it below:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "play_slot_machine()",
   "metadata": {},
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "By the way, did we mention that each play costs $1? Don't worry, we'll send you the bill later.\n\nOn average, how much money can you expect to gain (or lose) every time you play the machine?  The casino keeps it a secret, but you can estimate the average value of each pull using a technique called the **Monte Carlo method**. To estimate the average outcome, we simulate the scenario many times, and return the average result.\n\nComplete the following function to calculate the average value per play of the slot machine.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def estimate_average_slot_payout(n_runs):\n    \"\"\"Run the slot machine n_runs times and return the average net profit per run.\n    Example calls (note that return value is nondeterministic!):\n    >>> estimate_average_slot_payout(1)\n    -1\n    >>> estimate_average_slot_payout(1)\n    0.5\n    \"\"\"\n    pass",
   "metadata": {},
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "When you think you know the expected value per spin, run the code cell below to view the solution and get credit for answering the question.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check your answer (Run this code cell to receive credit!)\nq4.solution()",
   "metadata": {},
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"4_ExpectedSlotsPayout\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Solution: The exact expected value of one pull of the slot machine is 0.025 - i.e. a little more than 2 cents. See? Not every game in the Python Challenge Casino is rigged against the player!\n\nBecause of the high variance of the outcome (there are some very rare high payout results that significantly affect the average) you might need to run your function with a very high value of `n_runs` to get a stable answer close to the true expectation.\n\nIf your answer is way higher than 0.025, then maybe you forgot to account for the $1 cost per play?",
      "text/markdown": "<span style=\"color:#33cc99\">Solution:</span> The exact expected value of one pull of the slot machine is 0.025 - i.e. a little more than 2 cents. See? Not every game in the Python Challenge Casino is rigged against the player!\n\nBecause of the high variance of the outcome (there are some very rare high payout results that significantly affect the average) you might need to run your function with a very high value of `n_runs` to get a stable answer close to the true expectation.\n\nIf your answer is way higher than 0.025, then maybe you forgot to account for the $1 cost per play?"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Keep Going\n\nMany programmers report that dictionaries are their favorite data structure. You'll get to **[learn about them](https://www.kaggle.com/colinmorris/strings-and-dictionaries)** (as well as strings) in the next lesson.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum/161283) to chat with other Learners.*",
   "metadata": {}
  }
 ]
}